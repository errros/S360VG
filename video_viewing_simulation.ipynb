{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:21:26.360251800Z",
     "start_time": "2024-04-30T14:21:26.344214600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "from sensor_projection_utils import equirect_point_to_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_fov_saliency_rate_and_target_point(frame, center, fov,previous_intr_coeff,change_significance_threshold=0.02,intr_threshold=0.95):\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    intensity_list = []\n",
    "    rect_width, rect_height = fov\n",
    "    max_intensity = 0\n",
    "\n",
    "    # Define the rectangle boundaries\n",
    "    left = max(center[0] - rect_width // 2, 0)\n",
    "    right = min(center[0] + rect_width // 2, frame.shape[1])\n",
    "    \n",
    "    #detect if there's a wraping in the equirectangular frame FoV (accounting for sphere movement)\n",
    "    left_rect  = False\n",
    "    right_rect = False\n",
    "    if left == 0:\n",
    "        right_rect = True\n",
    "        print(\"right wrap case\")\n",
    "    if right == frame.shape[1]:\n",
    "        left_rect = True\n",
    "        print(\"left wrap case\")\n",
    "   \n",
    "        \n",
    "        \n",
    "    \n",
    "    top = max(center[1] - rect_height // 2, 0)\n",
    "    bottom = min(center[1] + rect_height // 2, frame.shape[0])\n",
    "\n",
    "    for x in range(left, right):\n",
    "        for y in range(top, bottom):\n",
    "            intensity = gray_frame[y, x]\n",
    "            intensity_list.append(((x, y,intensity), intensity))\n",
    " \n",
    "    if left_rect:\n",
    "        rect_wid =  rect_width // 2\n",
    "        for x in range(1, rect_wid):\n",
    "            for y in range(top, bottom):\n",
    "                intensity = gray_frame[y, x]\n",
    "                intensity_list.append(((x, y,intensity), intensity))\n",
    "    \n",
    "    if right_rect:\n",
    "        rect_wid =  rect_width // 2\n",
    "        for x in range(frame.shape[1] - rect_wid, frame.shape[1]):\n",
    "            for y in range(top, bottom):\n",
    "                intensity = gray_frame[y, x]\n",
    "                intensity_list.append(((x, y,intensity), intensity))\n",
    "     \n",
    "\n",
    "        \n",
    "    random.shuffle(intensity_list)     \n",
    "    \n",
    "    low_intensities_count = sum(1 for intensity in intensity_list if intensity[1] < 30)\n",
    " \n",
    "    low_percentage = (low_intensities_count / len(intensity_list))\n",
    "    \n",
    "    #check if there's no movement\n",
    "    if (np.abs(low_percentage - previous_intr_coeff)  <= change_significance_threshold and low_percentage <intr_threshold):\n",
    "        return None,low_percentage\n",
    "        \n",
    "    \n",
    "    # Sort by intensity and pick the top 3\n",
    "   \n",
    "    top_3 = sorted(intensity_list, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "    if len(intensity_list) == 0 :\n",
    "        return center\n",
    "    #return target point\n",
    "    return random.choice(top_3)[0],low_percentage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:21:26.959033300Z",
     "start_time": "2024-04-30T14:21:26.936094200Z"
    }
   },
   "id": "f618194a403b2d4f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def simulation(input_video_env_path,output_trajectory_csv_path, frame_range, X_Mov_law, Y_Mov_law, fov_dimensions=(720,720),change_significance_threshold=0.02,intr_threshold=0.95 , adjustment_threshold=0.98):\n",
    "    \n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(columns=[\"Frame.No\",'X','Y','X_pixel','Y_pixel','X_mov','Y_mov'])\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_env_path)\n",
    "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    #randomly initialize initial agent movement\n",
    "    X, Y = norm(loc=0.63, scale=0.29).rvs(),norm(loc=0.52, scale=0.13).rvs()\n",
    "\n",
    "    dx ,dy = 0,0\n",
    "    \n",
    "    intrest_rate = 1\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count > frame_range[1]:\n",
    "            break\n",
    "        if frame_count >= frame_range[0]:\n",
    "            \n",
    "            # the norm(loc=0.0, scale=0.001) is the noise\n",
    "            X += dx + norm(loc=0.0, scale=0.001).rvs()\n",
    "            Y += dy + norm(loc=0.0, scale=0.001).rvs()\n",
    "            \n",
    "            #Frame wrapping\n",
    "            if X>1.25:\n",
    "                X = (X - 1.25) + 0.25 \n",
    "            if X<0.25:\n",
    "                X = 1.25 - abs(0.25 - X)  \n",
    "            \n",
    "            X_pixel, Y_pixel = equirect_point_to_pixels([X,Y],[width,height]) \n",
    "            X_pixel, Y_pixel = int(X_pixel) , int(Y_pixel)\n",
    "           \n",
    "            \n",
    "            \n",
    "            df.loc[len(df)] = [frame_count, X, Y, X_pixel, Y_pixel, dx, dy]                \n",
    "      \n",
    "            print(f'frame is {frame_count}')\n",
    "             \n",
    "                  \n",
    "            if frame_count % 10 == 0:\n",
    "                \n",
    "                X_mov , Y_mov = 0,0\n",
    "                target_point,intrest_rate = get_fov_saliency_rate_and_target_point(frame, (X_pixel, Y_pixel), fov_dimensions , intrest_rate,change_significance_threshold=0.02,intr_threshold=0.95)\n",
    "                \n",
    "                if target_point is not None:\n",
    "                    X_mov = np.abs(norm(loc=X_Mov_law[0], scale=X_Mov_law[1]).rvs())\n",
    "                    Y_mov = np.abs(norm(loc=Y_Mov_law[0], scale=Y_Mov_law[1]).rvs())    \n",
    "                   \n",
    "                    if intrest_rate <adjustment_threshold:\n",
    "                        #Movement direction         \n",
    "                        if target_point[0] < X_pixel:\n",
    "                            X_mov = X_mov * -1\n",
    "                        if target_point[1] < Y_pixel:\n",
    "                            Y_mov = Y_mov * -1\n",
    "                    \n",
    "                    #adjsut agent to the center of the environment\n",
    "                    elif intrest_rate >=adjustment_threshold:\n",
    "                         center = int(height / 2) \n",
    "                         \n",
    "                                                       \n",
    "                         if Y_pixel<center:\n",
    "                             Y_mov = Y_mov*2\n",
    "                         else :    \n",
    "                             Y_mov = Y_mov*-2\n",
    "                            \n",
    "                dx = X_mov /10 \n",
    "                dy = Y_mov / 10 \n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "    df.to_csv(output_trajectory_csv_path,index=False)        \n",
    "    cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:21:27.482971300Z",
     "start_time": "2024-04-30T14:21:27.463025900Z"
    }
   },
   "id": "c56a661d6baa2578"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1,49):\n",
    "    print(\"-----------------------------\")\n",
    "    print(f\"Synthetic Agent {i}\")\n",
    "    simulation(\"./002-sal-eml.mp4\",f\"./sal2-eml/002-syn-u{i}.csv\", [1,1800],[0.013327,0.023678], [0.0073,0.01352], [720,720])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26aa8eae83a99f1b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#draw in a frame a rectangle around a fixation point representing the simplified FoV of a user\n",
    "def draw_fov(frame, center, dimensions,border_color=(0, 255, 0)):\n",
    "    rect_width, rect_height = dimensions\n",
    "    top_left = (center[0] - rect_width // 2, center[1] - rect_height // 2)\n",
    "    bottom_right = (center[0] + rect_width // 2, center[1] + rect_height // 2)\n",
    "    cv2.rectangle(frame, top_left, bottom_right, border_color, 2)\n",
    "\n",
    "def simulation_visualization(video_path, trajectory_path, output_video_path, fixation_color=(0, 0, 255), fov_dimensions=(720, 720),fov_border_color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Reads a DataFrame with frame information, processes a video,\n",
    "    draws fixations and FoV on specified frames,representing user head movements and saves a new video.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(trajectory_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        frame_no = row['Frame.No'] - 1  # Adjust for zero-based indexing\n",
    "        print(frame_no)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        if ret:\n",
    "            x_pixel = int(row['X_pixel'])\n",
    "            y_pixel = int(row['Y_pixel'])\n",
    "    \n",
    "            cv2.circle(frame, (x_pixel, y_pixel), 15, fixation_color, -1)  # Draw point\n",
    "            draw_fov(frame, [x_pixel,y_pixel], fov_dimensions)\n",
    "    \n",
    "            out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:52:52.282074200Z",
     "start_time": "2024-04-30T14:52:52.254653100Z"
    }
   },
   "id": "eb36191c7b268e83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simulation_visualization(\"./002-sal-eml.mp4\", \"./sal2-eml/002-syn-u1.csv\", \"./trajectory-video2-user1.mp4\", fixation_color=(0, 0, 255), fov_dimensions=(720, 720),fov_border_color=(0, 255, 0))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb0d1ae945a9fae0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6413612faa6a66c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
